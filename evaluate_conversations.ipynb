{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def roberta_model(classifier, text):\n",
    "    out = classifier(text)\n",
    "    \n",
    "    emotions = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'neutral', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise']\n",
    "    out = {d['label']: d['score'] for d in out[0]}\n",
    "    out = [out[em] for em in emotions]\n",
    "    out = np.asarray(out)\n",
    "    #print(out.shape)\n",
    "    return out\n",
    "\n",
    "def fake_model(input):\n",
    "    return [0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from functools import partial\n",
    "\n",
    "def compute_emotions_per_segment(phase, model):\n",
    "\n",
    "    player_df = phase[phase[\"Person\"] == \"Player\"].drop(columns=[\"Person\"])\n",
    "    #print(player_df)\n",
    "    player_text = player_df[\"Text\"].values\n",
    "    \n",
    "    y = []\n",
    "    for text in player_text:\n",
    "        # Compute emotion vector (this should be a vector of floats (bert scores, avg of llm outputs))\n",
    "        out = model(text)\n",
    "        y.append(out)\n",
    "        #print(out)\n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "def compute_emotions_per_word_window(phase, model, window_size=10):\n",
    "\n",
    "    player_df = phase[phase[\"Person\"] == \"Player\"].drop(columns=[\"Person\"])\n",
    "    player_text = player_df[\"Text\"].values\n",
    "\n",
    "    full_text = \". \".join(player_text)\n",
    "    print(full_text)\n",
    "    \n",
    "    words = full_text.split(\" \")\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(words) - window_size):\n",
    "        # Compute emotion vector (this should be a vector of floats (bert scores, avg of llm outputs))\n",
    "        text = \" \".join(words[i:i+window_size])\n",
    "        out = model(text)\n",
    "        y.append(out)\n",
    "        #print(out)\n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def compute_scores_from_convologs(filename, model, output_info=\"\"):\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(filename, sep=\",\")\n",
    "    df.head()\n",
    "    \n",
    "    sessions = df[\"Session\"].unique()\n",
    "    print(sessions)\n",
    "\n",
    "    for session_id in sessions:\n",
    "        print(session_id)\n",
    "\n",
    "        # Split text in phases\n",
    "        session_df = df[df[\"Session\"] == session_id].drop(columns=[\"Session\"])\n",
    "        #print(session_df)\n",
    "        phases = [session_df[session_df[\"Phase\"] == i+1].drop(columns=[\"Phase\"]) for i in range(3)]\n",
    "\n",
    "        # Compute emotions per line / per segment\n",
    "        # Save output sequence s{s_id}_ph{i}_model{m}.csv\n",
    "        # Can also have p_line/p_seg in the name to test both\n",
    "        #seg_emotions = [compute_emotions_per_segment(phases[i], model) for i in range(3)]\n",
    "        seg_emotions = [compute_emotions_per_word_window(phases[i], model) for i in range(3)]\n",
    "\n",
    "        intro_seg_avg = seg_emotions[0]#.mean(axis=0)\n",
    "        outro_seg_avg = seg_emotions[2]#.mean(axis=0)\n",
    "        middle_per_seg = seg_emotions[1]\n",
    "\n",
    "        # check if any value is nan\n",
    "        has_nan_in_scores = np.isnan(np.sum(intro_seg_avg)) or np.isnan(np.sum(outro_seg_avg)) or np.isnan(np.sum(middle_per_seg))\n",
    "        has_empty_scores = np.sum(intro_seg_avg) == 0 or np.sum(outro_seg_avg) == 0 or np.sum(middle_per_seg) == 0\n",
    "        if has_nan_in_scores or has_empty_scores:\n",
    "            print(f\"[s{session_id} - Some values are missing, skipping this session\")\n",
    "            continue\n",
    "\n",
    "        intro_seg_avg = intro_seg_avg.mean(axis=0)\n",
    "        outro_seg_avg = outro_seg_avg.mean(axis=0)\n",
    "        \n",
    "        # NPC emotion\n",
    "        NPC_name = phases[1][\"Phase2 NPC emotion\"].unique()\n",
    "        print(NPC_name)\n",
    "        assert len(NPC_name) <= 1\n",
    "        NPC_name = NPC_name[0]\n",
    "        NPC_emotion = NPC_name.split(\"(\")[1].split(\")\")[0]\n",
    "        print(NPC_name, NPC_emotion)\n",
    "\n",
    "        # Session scores\n",
    "        scores = {\n",
    "            \"intro\": intro_seg_avg,\n",
    "            \"outro\": outro_seg_avg,\n",
    "            \"middle\": middle_per_seg,\n",
    "            \"middle_emotion\": NPC_emotion,\n",
    "        }\n",
    "        #print(scores)\n",
    "\n",
    "        filename = f\"data/results/{session_id}_scores.pkl\" if output_info == \"\" else f\"data/results/{session_id}_{output_info}_scores.pkl\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(scores, f)\n",
    "\n",
    "\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None, max_length=512, truncation=True)\n",
    "filename = \"./data/VG4R-Blackstories-convologs - Data(3).csv\"\n",
    "\n",
    "compute_scores_from_convologs(filename, partial(roberta_model, classifier), output_info=\"roberta_wordwindow10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
